opencl open computing language opencl is a framework for writing programs that execute across heterogeneous platforms consisting of central processing units cpus graphics processing units gpus digital signal processors dsps fieldprogrammable gate arrays fpgas and other processors or hardware accelerators opencl specifies a programming language based on c for programming these devices and application programming interfaces apis to control the platform and execute programs on the compute devices opencl provides a standard interface for parallel computing using taskbased and databased parallelism opencl is an open standard maintained by the nonprofit technology consortium khronos group conformant implementations are available from altera amd apple arm holdings creative technology ibm imagination technologies intel nvidia qualcomm samsung vivante xilinx and ziilabs overview opencl views a computing system as consisting of a number of compute devices which might be central processing units cpus or accelerators such as graphics processing units gpus attached to a host processor a cpu it defines a clike language for writing programs functions executed on an opencl device are called kernels a single compute device typically consists of several compute units which in turn comprise multiple processing elements pes a single kernel execution can run on all or many of the pes in parallel how a compute device is subdivided into compute units and pes is up to the vendor a compute unit can be thought of as a core but the notion of core is hard to define across all the types of devices supported by opencl or even within the category of cpus and the number of compute units may not correspond to the number of cores claimed in vendors marketing literature which may actually be counting simd lanes in addition to its clike programming language opencl defines an application programming interface api that allows programs running on the host to launch kernels on the compute devices and manage device memory which is at least conceptually separate from host memory programs in the opencl language are intended to be compiled at runtime so that openclusing applications are portable between implementations for various host devices the opencl standard defines host apis for c and c thirdparty apis exist for other programming languages and platforms such as python java and net an implementation of the opencl standard consists of a library that implements the api for c and c and an opencl c compiler for the compute devices targeted memory hierarchy opencl defines a fourlevel memory hierarchy for the compute device not every device needs to implement each level of this hierarchy in hardware consistency between the various levels in the hierarchy is relaxed and only enforced by explicit synchronization constructs notably barriers devices may or may not share memory with the host cpu the host api provides handles on device memory buffers and functions to transfer data back and forth between host and devices opencl c language the programming language that is used to write compute kernels is called opencl c and is based on c but adapted to fit the device model in opencl memory buffers reside in specific levels of the memory hierarchy and pointers are annotated with the region qualifiers    and  reflecting this instead of a device program having a function opencl c functions are marked to signal that they are entry points into the program to be called from the host program function pointers bit fields and variablelength arrays are omitted recursion is forbidden the c standard library is replaced by a custom set of standard functions geared toward math programming opencl c is extended to facilitate use of parallelism with vector types and operations synchronization and functions to work with workitems and workgroups in particular besides scalar types such as and  which behave similarly to the corresponding types in c opencl provides fixedlength vector types such as vector of singleprecision floats such vector types are available in lengths two three four eight and sixteen for various base types vectorized operations on these types are intended to map onto simd instructions sets eg sse or vmx when running opencl programs on cpus other specialized types include d and d image types example matrixvector multiplication the following is a matrixvector multiplication algorithm in opencl c  multiplies ax leaving the result in y  a is a rowmajor matrix meaning the ij element is at aincolsj kernel void matvecglobal const float a global const float x the kernel function computes in each invocation the dot product of a single row of a matrix and a vector  to extend this into a full matrixvector multiplication the opencl runtime maps the kernel over the rows of the matrix on the host side the function does this it takes as arguments the kernel to execute its arguments and a number of workitems corresponding to the number of rows in the matrix  example computing the fft this example will load a fast fourier transform fft implementation and execute it the implementation is shown below the actual calculation based on fitting fft onto the g architecture a full open source implementation of an opencl fft can be found on apples website history opencl was initially developed by apple inc which holds trademark rights and refined into an initial proposal in collaboration with technical teams at amd ibm qualcomm intel and nvidia apple submitted this initial proposal to the khronos group on june   the khronos compute working group was formed with representatives from cpu gpu embeddedprocessor and software companies this group worked for five months to finish the technical details of the specification for opencl  by november   this technical specification was reviewed by the khronos members and approved for public release on december   opencl  opencl  released with mac os x snow leopard on august   according to an apple press release snow leopard further extends support for modern hardware with open computing language opencl which lets any application tap into the vast gigaflops of gpu computing power previously available only to graphics applications opencl is based on the c programming language and has been proposed as an open standard amd decided to support opencl instead of the now deprecated close to metal in its stream framework rapidmind announced their adoption of opencl underneath their development platform to support gpus from multiple vendors with one interface on december   nvidia announced its intention to add full support for the opencl  specification to its gpu computing toolkit on october   ibm released its first opencl implementation as a part of the xl compilers opencl  opencl  was ratified by the khronos group on june   and adds significant functionality for enhanced parallel programming flexibility functionality and performance including opencl  on november   the khronos group announced the opencl  specification which added significant functionality over the previous versions in terms of performance and features for parallel programming most notable features include opencl  on november   the khronos group announced the ratification and public release of the finalized opencl  specification updates and additions to opencl  include opencl  the ratification and release of the opencl  provisional specification was announced on march   at the game developer conference in san francisco it was released on november   it replaces the opencl c kernel language with opencl c a subset of c vulkan and opencl  share spirv as an intermediate representation allowing highlevel language frontends to share a common compilation target updates to the opencl api include amd arm intel hpc and yetiware have declared support for opencl  opencl  opencl  brings the opencl c kernel language into the core specification for significantly enhanced parallel programming productivity implementations opencl consists of a set of headers and a shared object that is loaded at runtime an installable client driver icd must be installed on the platform for every class of vendor for which the runtime would need to support that is for example in order to support nvidia devices on a linux platform the nvidia icd would need to be installed such that the opencl runtime the icd loader would be able to locate the icd for the vendor and redirect the calls appropriately the standard opencl header is used by the consumer application calls to each function are then proxied by the opencl runtime to the appropriate driver using the icd each vendor must implement each opencl call in their driver a number of open source implementations of the opencl icd exist including freeocl and oclicd an implementation of opencl for a number of platforms is maintained as part of the gallium compute project which builds on the work of the mesa project to support multiple platforms an implementation by intel for its ivy bridge hardware was released in  this software called beignet is not based on mesagallium which has attracted criticism from developers at amd and red hat as well as michael larabel of phoronix a cpuonly version building on clang and llvm called pocl is intended to be a portable opencl implementation devices as of  opencl runs on graphics processing units cpus with simd instructions fpgas movidius myriad  adapteva epiphany and dsps conformant products the khronos group maintains an extended list of openclconformant products extensions some vendors provide extended functionality over the standard opencl specification via the means of extensions these are still specified by khronos but provided by vendors within their sdks they often contain features that are to be implemented in the future  for example device fission functionality was originally an extension but is now provided as part of the  specification extensions provided in the  specification include device fission device fission  introduced fully into the opencl standard with version   allows individual command queues to be used for specific areas of a device for example within the intel sdk a command queue can be created that maps directly to an individual core amd also provides functionality for device fission also originally as an extension device fission can be used where the availability of compute is required reliably such as in a latency sensitive environment fission effectively reserves areas of the device for computation portability performance and alternatives a key feature of opencl is portability via its abstracted memory and execution model and the programmer is not able to directly use hardwarespecific technologies such as inline parallel thread execution ptx for nvidia gpus unless they are willing to give up direct portability on other platforms it is possible to run any opencl kernel on any conformant implementation however performance of the kernel is not necessarily portable across platforms existing implementations have been shown to be competitive when kernel code is properly tuned though and autotuning has been suggested as a solution to the performance portability problem yielding acceptable levels of performance in experimental linear algebra kernels portability of an entire application containing multiple kernels with differing behaviors was also studied and shows that portability only required limited tradeoffs a study at delft university that compared cuda programs and their straightforward translation into opencl c found cuda to outperform opencl by at most  on the nvidia implementation the researchers noted that their comparison could be made fairer by applying manual optimizations to the opencl programs in which case there was no reason for opencl to obtain worse performance than cuda the performance differences could mostly be attributed to differences in the programming model especially the memory model and to nvidias compiler optimizations for cuda compared to those for opencl another study at dwave systems inc found that the opencl kernels performance is between about  and  slower and the endtoend time is between about  and  slower than cudas performance the fact that opencl allows workloads to be shared by cpu and gpu executing the same programs means that programmers can exploit both by dividing work among the devices this leads to the problem of deciding how to partition the work because the relative speeds of operations differ among the devices machine learning has been suggested to solve this problem grewe and oboyle describe a system of support vector machines trained on compiletime features of program that can decide the device partitioning problem statically without actually running the programs to measure their performance