parallel programming model in computing a parallel programming model is an abstraction of parallel computer architecture with which it is convenient to express algorithms and their composition in programs the value of a programming model can be judged on its generality how well a range of different problems can be expressed for a variety of different architectures and its performance how efficiently the compiled programs can execute the implementation of a parallel programming model can take the form of a library invoked from a sequential language as an extension to an existing language or as an entirely new language consensus around a particular programming model is important because it leads to different parallel computers being built with support for the model thereby facilitating portability of software in this sense programming models are referred to as bridging between hardware and software classification of parallel programming models classifications of parallel programming models can be divided broadly into two areas process interaction and problem decomposition process interaction process interaction relates to the mechanisms by which parallel processes are able to communicate with each other the most common forms of interaction are shared memory and message passing but interaction can also be implicit invisible to the programmer shared memory shared memory is an efficient means of passing data between processes in a sharedmemory model parallel processes share a global address space that they read and write to asynchronously asynchronous concurrent access can lead to race conditions and mechanisms such as locks semaphores and monitors can be used to avoid these conventional multicore processors directly support shared memory which many parallel programming languages and libraries such as cilk openmp and threading building blocks are designed to exploit message passing in a messagepassing model parallel processes exchange data through passing messages to one another these communications can be asynchronous where a message can be sent before the receiver is ready or synchronous where the receiver must be ready the communicating sequential processes csp formalisation of message passing uses synchronous communication channels to connect processes and led to important languages such as occam limbo and go in contrast the actor model uses asynchronous message passing and has been employed in the design of languages such as d scala and salsa implicit interaction in an implicit model no process interaction is visible to the programmer and instead the compiler andor runtime is responsible for performing it two examples of implicit parallelism are with domainspecific languages where the concurrency within highlevel operations is prescribed and with functional programming languages because the absence of sideeffects allows nondependent functions to be executed in parallel however this kind of parallelism is difficult to manage and functional languages such as concurrent haskell and concurrent ml provide features to manage parallelism explicitly problem decomposition a parallel program is composed of simultaneously executing processes problem decomposition relates to the way in which the constituent processes are formulated task parallelism a taskparallel model focuses on processes or threads of execution these processes will often be behaviourally distinct which emphasises the need for communication task parallelism is a natural way to express messagepassing communication in flynns taxonomy task parallelism is usually classified as mimdmpmd or misd data parallelism a dataparallel model focuses on performing operations on a data set typically a regularly structured array a set of tasks will operate on this data but independently on disjoint partitions in flynns taxonomy data parallelism is usually classified as mimdspmd or simd implicit parallelism as with implicit process interaction an implicit model of parallelism reveals nothing to the programmer as the compiler the runtime or the hardware is responsible for example in compilers automatic parallelization is the process of converting sequential code into parallel code and in computer architecture superscalar execution is a mechanism whereby instructionlevel parallelism is exploited to perform operations in parallel terminology parallel programming models are closely related to models of computation a model of parallel computation is an abstraction used to analyze the cost of computational processes but it does not necessarily need to be practical in that it can be implemented efficiently in hardware andor software a programming model in contrast does specifically imply the practical considerations of hardware and software implementation a parallel programming language may be based on one or a combination of programming models for example high performance fortran is based on sharedmemory interactions and dataparallel problem decomposition and go provides mechanism for sharedmemory and messagepassing interaction